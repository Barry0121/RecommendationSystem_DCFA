{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import random\n",
    "import json\n",
    "import scipy\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import defaultdict\n",
    "import os\n",
    "tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data.py"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Storing User, Item, Time tuples in `interactionTrain`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# put the \"dataset\" folder in the root directory\n",
    "base = 'dataset'\n",
    "# if base not in os.listdir('./'):\n",
    "#     print(os.curdir)\n",
    "#     print(\"dataset folder not found.\")\n",
    "#     # break # made available in the final py file\n",
    "# else:\n",
    "interactions_Jewelry_train = os.path.join(base, 'interactions_Jewelry_train.json')\n",
    "interactions_Jewelry_train_aux = os.path.join(base, 'interactions_Jewelry_train_aux.json')\n",
    "interactions_Jewelry_train_record = os.path.join(base, 'interactions_Jewelry_train_record_aux.json')\n",
    "interactions_Jewelry_train_time = os.path.join(base, 'interactions_Jewelry_train_time_aux.json')\n",
    "interactions_Jewelry_validate = os.path.join(base, 'interactions_Jewelry_validate.json')\n",
    "interactions_Jewelry_test = os.path.join(base, 'interactions_Jewelry_test.json')\n",
    "CNN_AES = \"CNN_AES_feature.txt\"\n",
    "id2num_dict = \"id2num_dict_Jewelry.json\"\n",
    "if CNN_AES not in os.listdir(os.path.join('.', base, \"features\")) or id2num_dict not in os.listdir(os.path.join('.', base, \"id2num_dict\")):\n",
    "    print(\"CNN_AES and id2num_dict folders not found.\")\n",
    "    # break\n",
    "else:\n",
    "    CNN_AES = os.path.join(base, \"features\", CNN_AES)\n",
    "    id2num_dict = os.path.join(base, \"id2num_dict\", id2num_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "userIDs = set()\n",
    "itemIDs = set()\n",
    "#interactionsTrain = []\n",
    "user_to_item = {}\n",
    "user_time_to_item = {}\n",
    "time_to_item = {}\n",
    "\n",
    "with open(interactions_Jewelry_train) as json_file:\n",
    "    data = json.load(json_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "for d in data:\n",
    "    u = d[0]\n",
    "    i = d[1]\n",
    "    r = d[2]\n",
    "    #interactionsTrain.append((u,i,r))\n",
    "    userIDs.add(u)\n",
    "    itemIDs.add(i)\n",
    "    if u in user_to_item:\n",
    "        user_to_item[u].add(i)\n",
    "    else:\n",
    "        user_to_item[u] = {i}\n",
    "    if (u,r) in user_time_to_item:\n",
    "        user_time_to_item[(u,r)].add(i)\n",
    "    else:\n",
    "        user_time_to_item[(u,r)] = {i}\n",
    "    if r in time_to_item:\n",
    "        time_to_item[r].add(i)\n",
    "    else:\n",
    "        time_to_item[r] = {i}\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Storing CNN-AES Feature in `cnn`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "with open(CNN_AES) as cnn_txt:\n",
    "    cnn = cnn_txt.readlines()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Read id2num_dict in which contains item id and the dictionary index"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "with open(id2num_dict) as id2num_dict_json:\n",
    "    id2num = id2num_dict_json.readlines()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*From Library.py*\n",
    "Functions for:\n",
    "- Model Evaluation\n",
    "- Data Reading"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import *\n",
    "from xlrd import open_workbook\n",
    "from xlutils.copy import copy\n",
    "import json\n",
    "\n",
    "\"\"\"\n",
    "Evaluation Metrics\n",
    "\"\"\"\n",
    "\n",
    "def evaluation_F1(order, top_k, positive_item):\n",
    "    e = 0.00000000000001\n",
    "    top_k_items = set(order[0: top_k])\n",
    "    positive_item = set(positive_item)\n",
    "    precision = len(top_k_items & positive_item) / (len(top_k_items) + e)\n",
    "    recall = len(top_k_items & positive_item) / (len(positive_item) + e)\n",
    "    F1 = 2 * precision * recall / (precision + recall + e)\n",
    "    return F1\n",
    "\n",
    "def evaluation_NDCG(order, top_k, positive_item):\n",
    "    top_k_item = order[0: top_k]\n",
    "    e = 0.0000000001\n",
    "    Z_u = 0\n",
    "    temp = 0\n",
    "    for i in range(0, top_k):\n",
    "        Z_u += 1 / log2(i + 2)\n",
    "        if top_k_item[i] in positive_item:\n",
    "            temp += 1 / log2(i + 2)\n",
    "    NDCG = temp / (Z_u + e)\n",
    "    return NDCG\n",
    "\n",
    "def save_result(intro, F1, NDCG, path):\n",
    "    rexcel = open_workbook(path)\n",
    "    rows = rexcel.sheets()[0].nrows\n",
    "    excel = copy(rexcel)\n",
    "    table = excel.get_sheet(0)\n",
    "    row = rows\n",
    "    table.write(row, 0, intro)\n",
    "    #table.write(row, 2, 'F1')\n",
    "    for i in range(len(F1)):\n",
    "        table.write(row, i + 3, F1[i])\n",
    "    #table.write(row, len(F1) + 4, 'NDCG')\n",
    "    for i in range(len(NDCG)):\n",
    "        table.write(row, i + len(F1) + 5, NDCG[i])\n",
    "    excel.save(path)\n",
    "\n",
    "\"\"\"\n",
    "Read Data\n",
    "\"\"\"\n",
    "def readdata(dataset):\n",
    "    #file paths\n",
    "    path_train = interactions_Jewelry_train\n",
    "    path_train_aux = interactions_Jewelry_train_aux\n",
    "    path_validate = interactions_Jewelry_validate\n",
    "    path_test = interactions_Jewelry_test\n",
    "    # read files\n",
    "    with open(path_train) as f:\n",
    "        line = f.readline()\n",
    "        train_data = json.loads(line)\n",
    "    f.close()\n",
    "    P = 0\n",
    "    Q = 0\n",
    "    for [u, i, r] in train_data:\n",
    "        if u > P:\n",
    "            P = u\n",
    "        if i > Q:\n",
    "            Q = i\n",
    "    with open(path_train_aux) as f:\n",
    "        line = f.readline()\n",
    "        train_data_aux = json.loads(line)\n",
    "    f.close()\n",
    "    with open(path_validate) as f:\n",
    "        line = f.readline()\n",
    "        validate_data = json.loads(line)\n",
    "    f.close()\n",
    "    with open(path_test) as f:\n",
    "        line = f.readline()\n",
    "        test_data = json.loads(line)\n",
    "    f.close()\n",
    "    return train_data, train_data_aux, validate_data, test_data, P + 1, Q + 1 # P: last user_id, last item_id\n",
    "\n",
    "def readdata_time(dataset):\n",
    "    #file paths\n",
    "    path_train_record_aux = interactions_Jewelry_train_record\n",
    "    path_train_time_aux = interactions_Jewelry_train_time\n",
    "    # read files\n",
    "    with open(path_train_record_aux) as f:\n",
    "        line = f.readline()\n",
    "        train_record_aux = json.loads(line)\n",
    "    f.close()\n",
    "    with open(path_train_time_aux) as f:\n",
    "        line = f.readline()\n",
    "        train_time_aux = json.loads(line)\n",
    "    f.close()\n",
    "    return train_record_aux, train_time_aux, len(train_time_aux)\n",
    "\n",
    "def read_feature(feature, dataset, Q):\n",
    "    path_feature = CNN_AES\n",
    "    path_dict = id2num_dict\n",
    "    with open(path_dict) as f:\n",
    "        line = f.readline()\n",
    "        item_i2num_dict = json.loads(line)\n",
    "    f.close()\n",
    "    f = open(path_feature, 'r')\n",
    "    line = eval(f.readline())\n",
    "    feature = line[1]\n",
    "    K = len(feature)\n",
    "    F = np.zeros((Q, K))\n",
    "    for i in range(0, Q):\n",
    "        F[i] = feature\n",
    "    for line in f:\n",
    "        line = eval(line)\n",
    "        item_id = line[0]\n",
    "        feature = line[1]\n",
    "        try:\n",
    "            item_num = item_i2num_dict[item_id]\n",
    "            F[item_num] = feature\n",
    "        except:\n",
    "            continue\n",
    "    return F\n",
    "\n",
    "def get_feature(dataset, Q):\n",
    "    # to load features\n",
    "    feat = [3]\n",
    "    feat_list = ['CNN', 'AES', 'CH', 'CNN_AES']             # feature list\n",
    "    F = read_feature(feat_list[feat[0]], dataset, Q)\n",
    "    for i in range(1, len(feat)):\n",
    "        F = np.hstack((F, read_feature(feat_list[feat[i]], dataset, Q)))\n",
    "    return F"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model.py"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "\n",
    "class DCFA(tf.keras.Model):\n",
    "    def __init__(self, P, Q, R, I, J, F, reg=1.5, mom=0.1):\n",
    "        \"\"\"\n",
    "        Initialization of the Visually_based Bayesian Personalized Ranking Model with Aesthetic Features\n",
    "\n",
    "        :param P: Number of Users\n",
    "        :param Q: Number of Items\n",
    "        :param R: Number of Time Intervals\n",
    "        :param I: Dimension of each Latent Items\n",
    "        :param J: Dimension of each Latent Items\n",
    "        :param F: The CNN-AES Feature Matrix\n",
    "        :param reg: regularize lambda\n",
    "        :param mom: momentum gamma\n",
    "        \"\"\"\n",
    "        super(DCFA, self).__init__()\n",
    "        # Latent Items\n",
    "        self.U = tf.Variable(np.array([np.array([(random.random() / math.sqrt(I)) for j in range(I)]) for i in range(P)]))\n",
    "        print(\"Dimension of U: \", self.U.shape)\n",
    "        self.V = tf.Variable(np.array([np.array([(random.random() / math.sqrt(I)) for j in range(I)]) for i in range(Q)]))\n",
    "        print(\"Dimension of V: \", self.V.shape)\n",
    "        self.W = tf.Variable(np.array([np.array([(random.random() / math.sqrt(J)) for j in range(J)]) for i in range(Q)]))\n",
    "        print(\"Dimension of W: \", self.W.shape)\n",
    "        self.T = tf.Variable(np.array([np.array([(random.random() / math.sqrt(J)) for j in range(J)]) for i in range(R)]))\n",
    "        print(\"Dimension of T: \", self.T.shape)\n",
    "        # Extract CNN-AES Features\n",
    "        self.F, self.K = F, len(F[0])\n",
    "        print(\"Dimension of F: \", self.F.shape)\n",
    "        print(\"Size of F: \", self.K)\n",
    "        self.M = tf.Variable(np.array([np.array([(random.random() / math.sqrt(self.K)) for j in range(self.K)]) for i in range(P)]))\n",
    "        print(\"Dimension of M: \", self.M.shape)\n",
    "        self.N = tf.Variable(np.array([np.array([(random.random() / math.sqrt(self.K)) for j in range(self.K)]) for i in range(R)]))\n",
    "        print(\"Dimension of N: \", self.N.shape)\n",
    "        # regularize coefficient and momentum coefficient\n",
    "        self.reg = reg\n",
    "        self.mom = mom\n",
    "        # self.top_k = [5, 10, 20, 50, 100]\n",
    "\n",
    "    def score(self, u, v, r):\n",
    "        \"\"\"\n",
    "        Given a (user, item, time) tuple, return the score associated with the relevancy of the given item to given user\n",
    "        at given timestamp\n",
    "\n",
    "        :param u: user_id\n",
    "        :param v: item_id\n",
    "        :param r: timestamp\n",
    "        :return: BPR score for the (user, item, time) tuple\n",
    "        \"\"\"\n",
    "        # B = (tf.expand_dims(self.U[u], axis=0) @ tf.transpose(self.V) + tf.expand_dims(self.M[u], axis=0) @ tf.transpose(self.F))[0][v]\n",
    "        # C = (tf.expand_dims(self.T[r], axis=0) @ tf.transpose(self.W) + tf.expand_dims(self.N[r], axis=0) @ tf.transpose(self.F))[0][v]\n",
    "        #print(B.shape, C.shape)\n",
    "        #return tf.tensordot(B, C, axes=0), B, C\n",
    "        # print(\"score\" + str(B*C))\n",
    "        # return B*C\n",
    "\n",
    "        B = tf.expand_dims(self.U[u], axis=0) @ tf.transpose(self.V) + tf.expand_dims(self.M[u], axis=0) @ tf.transpose(self.F)\n",
    "        C = tf.expand_dims(self.T[r], axis=0) @ tf.transpose(self.W) + tf.expand_dims(self.N[r], axis=0) @ tf.transpose(self.F)\n",
    "        # print(\"B Shape: \", B.shape)\n",
    "        # print(\"C Shape: \", C.shape)\n",
    "        # print(\"A Shape: \", (tf.squeeze(B)*tf.squeeze(C)).shape)\n",
    "        return (tf.squeeze(B)*tf.squeeze(C))[v], tf.squeeze(B)[v], tf.squeeze(C)[v]\n",
    "\n",
    "    def score_batch(self, u, r):\n",
    "        \"\"\"\n",
    "        Given a (user, time) pair, return an array of scores associated with the given user and given time\n",
    "        :param u:\n",
    "        :param r:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        B = tf.expand_dims(self.U[u], axis=0) @ tf.transpose(self.V) + tf.expand_dims(self.M[u], axis=0) @ tf.transpose(self.F)\n",
    "        C = tf.expand_dims(self.T[r], axis=0) @ tf.transpose(self.W) + tf.expand_dims(self.N[r], axis=0) @ tf.transpose(self.F)\n",
    "        return tf.squeeze(B)*tf.squeeze(C), tf.squeeze(B), tf.squeeze(C)\n",
    "\n",
    "    def call(self, u, v, v_prime, r):\n",
    "        \"\"\"\n",
    "        Calculate the BPR_OPT distance, which is a metric that measures the scoring distance between positive sample\n",
    "        and the negative sample of the given (user, item, time) tuple\n",
    "\n",
    "        :param u: user_id\n",
    "        :param v: item_id\n",
    "        :param v_prime: negative sample of item_id\n",
    "        :param r: timestamp\n",
    "        :return: loss value for the given tuple\n",
    "        \"\"\"\n",
    "        A_i, B_i, C_i = self.score(u, v, r)\n",
    "        A_j, B_j, C_j = self.score(u, v_prime, r)\n",
    "\n",
    "        # print(\"B_ij: \", B_i-B_j)\n",
    "        # print(\"C_ij: \", C_i-C_j)\n",
    "\n",
    "        A_loss = tf.math.log(tf.keras.activations.sigmoid(A_i-A_j))\n",
    "        B_loss = tf.math.log(tf.keras.activations.sigmoid(B_i-B_j))\n",
    "        C_loss = tf.math.log(tf.keras.activations.sigmoid(C_i-C_j))\n",
    "        # B_loss = tf.keras.activations.sigmoid(B_i-B_j)\n",
    "        # C_loss = tf.keras.activations.sigmoid(C_i-C_j)\n",
    "\n",
    "        # print(\"A loss: \", A_loss)\n",
    "        # print(\"B loss: \", B_loss)\n",
    "        # print(\"C loss: \", C_loss)\n",
    "\n",
    "        return tf.convert_to_tensor(A_loss + self.mom * B_loss + self.mom * C_loss)\n",
    "        # TODO: Fix Lambda regularization term (i.e. self.reg and self.mom)\n",
    "\n",
    "    def reg(self):\n",
    "        \"\"\"\n",
    "        Return the regularization value for the current latent terms\n",
    "\n",
    "        :return: regularization term\n",
    "        \"\"\"\n",
    "        return self.lamb * (tf.reduce_sum(self.betaU**2) + tf.reduce_sum(self.betaI**2) +\n",
    "                            tf.reduce_sum(self.gammaU**2) + tf.reduce_sum(self.gammaI**2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Engine.py"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "class engine():\n",
    "    def __init__(self, learning_rate=1e-3, batch_size=64, k=5):\n",
    "        \"\"\"\n",
    "\n",
    "        :param n_size:\n",
    "        \"\"\"\n",
    "\n",
    "        self.optimizer = None\n",
    "        self.model = None\n",
    "\n",
    "        # define hyperparameter\n",
    "        self.k = k\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = learning_rate\n",
    "\n",
    "        # save data\n",
    "        self.userIDs = set()\n",
    "        self.itemIDs = set()\n",
    "        self.user_to_item = {}\n",
    "        self.user_time_to_item = {}\n",
    "        self.time_to_item = {}\n",
    "\n",
    "        # self.train, self.test\n",
    "        self.cnn = None\n",
    "        self.id2num = None\n",
    "        self.train_data = None\n",
    "        self.train_data_aux = None\n",
    "        self.validate_data = None\n",
    "        self.test_data = None\n",
    "        self.train_record_aux = None\n",
    "        self.train_time_aux = None\n",
    "        self.R = None\n",
    "        self.P = None\n",
    "        self.Q = None\n",
    "        self.F = None\n",
    "\n",
    "\n",
    "    def run(self):\n",
    "        self.read_data()\n",
    "        self.read_feature_data()\n",
    "        self.create_model()\n",
    "\n",
    "\n",
    "    def train_batch(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def test_batch(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "    def read_data(self):\n",
    "        # put the \"dataset\" folder in the root directory\n",
    "        base = 'dataset'\n",
    "        if base not in os.listdir('./'):\n",
    "            print(os.curdir)\n",
    "            print(\"dataset folder not found.\")\n",
    "            # break # made available in the final py file\n",
    "        else:\n",
    "            interactions_Jewelry_train = os.path.join(base, 'interactions_Jewelry_train.json')\n",
    "            interactions_Jewelry_train_aux = os.path.join(base, 'interactions_Jewelry_train_aux.json')\n",
    "            interactions_Jewelry_train_record = os.path.join(base, 'interactions_Jewelry_train_record_aux.json')\n",
    "            interactions_Jewelry_train_time = os.path.join(base, 'interactions_Jewelry_train_time_aux.json')\n",
    "            interactions_Jewelry_validate = os.path.join(base, 'interactions_Jewelry_validate.json')\n",
    "            interactions_Jewelry_test = os.path.join(base, 'interactions_Jewelry_test.json')\n",
    "            CNN_AES = \"CNN_AES_feature.txt\"\n",
    "            id2num_dict = \"id2num_dict_Jewelry.json\"\n",
    "        if CNN_AES not in os.listdir(os.path.join('.', base, \"features\")) or id2num_dict not in os.listdir(os.path.join('.', base, \"id2num_dict\")):\n",
    "            print(\"CNN_AES and id2num_dict folders not found.\")\n",
    "            # break\n",
    "        else:\n",
    "            CNN_AES = os.path.join(base, \"features\", CNN_AES)\n",
    "            id2num_dict = os.path.join(base, \"id2num_dict\", id2num_dict)\n",
    "\n",
    "        #May need to add more\n",
    "        self.read_interaction_data(interactions_Jewelry_train)\n",
    "\n",
    "\n",
    "    def read_interaction_data(self, filePath, data_size=50):\n",
    "        with open(filePath) as json_file:\n",
    "            data = json.load(json_file)\n",
    "\n",
    "        for d in data[:data_size]:\n",
    "            u = d[0]\n",
    "            i = d[1]\n",
    "            r = d[2]\n",
    "            #interactionsTrain.append((u,i,r))\n",
    "            self.userIDs.add(u)\n",
    "            self.itemIDs.add(i)\n",
    "            if u in self.user_to_item:\n",
    "                self.user_to_item[u].add(i)\n",
    "            else:\n",
    "                self.user_to_item[u] = {i}\n",
    "            if (u,r) in self.user_time_to_item:\n",
    "                self.user_time_to_item[(u,r)].add(i)\n",
    "            else:\n",
    "                self.user_time_to_item[(u,r)] = {i}\n",
    "            if r in self.time_to_item:\n",
    "                self.time_to_item[r].add(i)\n",
    "            else:\n",
    "                self.time_to_item[r] = {i}\n",
    "\n",
    "\n",
    "    def read_feature_data(self):\n",
    "        with open(CNN_AES) as cnn_txt:\n",
    "            self.cnn = cnn_txt.readlines()\n",
    "        with open(id2num_dict) as id2num_dict_json:\n",
    "            self.id2num = id2num_dict_json.readlines()\n",
    "\n",
    "        # setup\n",
    "        feat = [3]                          # feature selecting, 0 for CNN, 1 for AES, 2 for CH, 3 for CNN+AES\n",
    "        dataset = 5                         # Datasets selecting 0 to 5 for 'All', '_Women', '_Men', '_CLothes', '_Shoes', '_Jewelry' respectively\n",
    "        dataset_list = ['', '_Women', '_Men', '_CLothes', '_Shoes', '_Jewelry']\n",
    "        # load data\n",
    "        self.train_data, self.train_data_aux, self.validate_data, self.test_data, self.P, self.Q = readdata(dataset_list[dataset])\n",
    "        # load data for tensor factorization\n",
    "        self.train_record_aux, self.train_time_aux, self.R = readdata_time(dataset_list[dataset])\n",
    "        # load features\n",
    "        self.F = get_feature(dataset_list[dataset], self.Q) # CNN_AES Features\n",
    "\n",
    "    def create_model(self):\n",
    "        self.model = DCFA(P=self.P, Q=self.Q, R=self.R, I=200, J=200, F=self.F, reg=1.5, mom=0.1)\n",
    "\n",
    "    #def create_negative(self):"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "pipe = engine()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 18:36:21.853853: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-03-10 18:36:21.854651: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of U:  (15924, 200)\n",
      "Dimension of V:  (3607, 200)\n",
      "Dimension of W:  (3607, 200)\n",
      "Dimension of T:  (238, 200)\n",
      "Dimension of F:  (3607, 1746)\n",
      "Size of F:  1746\n",
      "Dimension of M:  (15924, 1746)\n",
      "Dimension of N:  (238, 1746)\n"
     ]
    }
   ],
   "source": [
    "pipe.run()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "(<tf.Tensor: shape=(), dtype=float64, numpy=0.05654044189814102>,\n <tf.Tensor: shape=(), dtype=float64, numpy=0.23054644127853194>,\n <tf.Tensor: shape=(), dtype=float64, numpy=0.24524534659735803>)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.model.score(12308, 7, 182)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=float64, numpy=-0.8334998114738152>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.model.call(12308, 0, 1, 182)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "21",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/bd/3fcn_cld06z1y5f68_qm162m0000gn/T/ipykernel_15321/23936574.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     11\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mnegative_item\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 13\u001B[0;31m \u001B[0mnegative_item\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnegative\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m21\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mitemIDs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0muser_time_to_item\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/var/folders/bd/3fcn_cld06z1y5f68_qm162m0000gn/T/ipykernel_15321/23936574.py\u001B[0m in \u001B[0;36mnegative\u001B[0;34m(u, itemIDs, user_items)\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mnegative\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mu\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mint\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mitemIDs\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mset\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0muser_items\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0muser_to_item\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mint\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0;34m\"\"\"Maybe get the user's historical interation items\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m     \u001B[0mhistorical_items\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0muser_items\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mu\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m     \u001B[0mitemIDs_list\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mitemIDs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;31m# POTENTIAL RUNTIME ISSUE\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m     \u001B[0mnegative_item\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mchoice\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mitemIDs_list\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 21"
     ]
    }
   ],
   "source": [
    "# Negative Sampling Function\n",
    "from random import choice\n",
    "\n",
    "def negative(u: int, itemIDs: set, user_items=user_to_item) -> int:\n",
    "    \"\"\"Maybe get the user's historical interation items\"\"\"\n",
    "    historical_items = list(user_items[u])\n",
    "    itemIDs_list = list(itemIDs) # POTENTIAL RUNTIME ISSUE\n",
    "    negative_item = choice(itemIDs_list)\n",
    "    while negative_item in historical_items:\n",
    "        negative_item = choice(itemIDs_list)\n",
    "    return negative_item\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, Loss: -0.8334998114738152\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "No registered 'ResourceApplyGradientDescent' OpKernel for 'GPU' devices compatible with node {{node ResourceApplyGradientDescent}}\n\t (OpKernel was found, but attributes didn't match) Requested Attributes: T=DT_DOUBLE, use_locking=true\n\t.  Registered:  device='GPU'; T in [DT_FLOAT]\n  device='CPU'; T in [DT_HALF]\n  device='CPU'; T in [DT_BFLOAT16]\n  device='CPU'; T in [DT_FLOAT]\n  device='CPU'; T in [DT_DOUBLE]\n  device='CPU'; T in [DT_COMPLEX64]\n  device='CPU'; T in [DT_COMPLEX128]\n [Op:ResourceApplyGradientDescent]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotFoundError\u001B[0m                             Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/bd/3fcn_cld06z1y5f68_qm162m0000gn/T/ipykernel_15321/2776079131.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     13\u001B[0m                                   pipe.model.call(12308, 0, 1, 182).numpy()))\n\u001B[1;32m     14\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 15\u001B[0;31m \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply_gradients\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgradients\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpipe\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrainable_variables\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     16\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m print(\"Step: {}, Loss: {}\".format(optimizer.iterations.numpy(),\n",
      "\u001B[0;32m~/miniforge3/envs/general/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py\u001B[0m in \u001B[0;36mapply_gradients\u001B[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001B[0m\n\u001B[1;32m    657\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    658\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0moptimizer_utils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstrategy_supports_no_merge_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 659\u001B[0;31m         return self._distributed_apply(strategy, grads_and_vars, name,\n\u001B[0m\u001B[1;32m    660\u001B[0m                                        apply_state)\n\u001B[1;32m    661\u001B[0m       \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/general/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py\u001B[0m in \u001B[0;36m_distributed_apply\u001B[0;34m(self, distribution, grads_and_vars, name, apply_state)\u001B[0m\n\u001B[1;32m    704\u001B[0m               \u001B[0;34m\"update\"\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0meagerly_outside_functions\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;34m\"update_\"\u001B[0m \u001B[0;34m+\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    705\u001B[0m               var.op.name):\n\u001B[0;32m--> 706\u001B[0;31m             update_op = distribution.extended.update(\n\u001B[0m\u001B[1;32m    707\u001B[0m                 var, apply_grad_to_update_var, args=(grad,), group=False)\n\u001B[1;32m    708\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdistribute\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0min_cross_replica_context\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/general/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\u001B[0m in \u001B[0;36mupdate\u001B[0;34m(self, var, fn, args, kwargs, group)\u001B[0m\n\u001B[1;32m   2590\u001B[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001B[1;32m   2591\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_container_strategy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mscope\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2592\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_update\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvar\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgroup\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2593\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2594\u001B[0m       return self._replica_ctx_update(\n",
      "\u001B[0;32m~/miniforge3/envs/general/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\u001B[0m in \u001B[0;36m_update\u001B[0;34m(self, var, fn, args, kwargs, group)\u001B[0m\n\u001B[1;32m   3644\u001B[0m     \u001B[0;31m# The implementations of _update() and _update_non_slot() are identical\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3645\u001B[0m     \u001B[0;31m# except _update() passes `var` as the first argument to `fn()`.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3646\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_update_non_slot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvar\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mvar\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mtuple\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgroup\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3647\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3648\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m_update_non_slot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcolocate_with\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshould_group\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/general/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\u001B[0m in \u001B[0;36m_update_non_slot\u001B[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001B[0m\n\u001B[1;32m   3650\u001B[0m     \u001B[0;31m# once that value is used for something.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3651\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mUpdateContext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcolocate_with\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3652\u001B[0;31m       \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3653\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0mshould_group\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3654\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/general/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    595\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    596\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mag_ctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mControlStatusCtx\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstatus\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mag_ctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mStatus\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mUNSPECIFIED\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 597\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    598\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    599\u001B[0m   \u001B[0;32mif\u001B[0m \u001B[0minspect\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0misfunction\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0minspect\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mismethod\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/general/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py\u001B[0m in \u001B[0;36mapply_grad_to_update_var\u001B[0;34m(var, grad)\u001B[0m\n\u001B[1;32m    687\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0;34m\"apply_state\"\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dense_apply_args\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    688\u001B[0m         \u001B[0mapply_kwargs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"apply_state\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mapply_state\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 689\u001B[0;31m       \u001B[0mupdate_op\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_resource_apply_dense\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgrad\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvar\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mapply_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    690\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0mvar\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconstraint\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    691\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcontrol_dependencies\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mupdate_op\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/general/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py\u001B[0m in \u001B[0;36m_resource_apply_dense\u001B[0;34m(self, grad, var, apply_state)\u001B[0m\n\u001B[1;32m    139\u001B[0m           use_nesterov=self.nesterov)\n\u001B[1;32m    140\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 141\u001B[0;31m       return tf.raw_ops.ResourceApplyGradientDescent(\n\u001B[0m\u001B[1;32m    142\u001B[0m           \u001B[0mvar\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mvar\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhandle\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    143\u001B[0m           \u001B[0malpha\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcoefficients\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"lr_t\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/general/lib/python3.8/site-packages/tensorflow/python/util/tf_export.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    402\u001B[0m           \u001B[0;34m'Please pass these args as kwargs instead.'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    403\u001B[0m           .format(f=f.__name__, kwargs=f_argspec.args))\n\u001B[0;32m--> 404\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    405\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    406\u001B[0m   \u001B[0;32mreturn\u001B[0m \u001B[0mtf_decorator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmake_decorator\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdecorator_argspec\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mf_argspec\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/general/lib/python3.8/site-packages/tensorflow/python/ops/gen_training_ops.py\u001B[0m in \u001B[0;36mresource_apply_gradient_descent\u001B[0;34m(var, alpha, delta, use_locking, name)\u001B[0m\n\u001B[1;32m   1938\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0m_result\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1939\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0m_core\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1940\u001B[0;31m       \u001B[0m_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraise_from_not_ok_status\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1941\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0m_core\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_FallbackException\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1942\u001B[0m       \u001B[0;32mpass\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/general/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001B[0m in \u001B[0;36mraise_from_not_ok_status\u001B[0;34m(e, name)\u001B[0m\n\u001B[1;32m   6939\u001B[0m   \u001B[0mmessage\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmessage\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;34m\" name: \"\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;34m\"\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6940\u001B[0m   \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 6941\u001B[0;31m   \u001B[0msix\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraise_from\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_status_to_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcode\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmessage\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   6942\u001B[0m   \u001B[0;31m# pylint: enable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6943\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/general/lib/python3.8/site-packages/six.py\u001B[0m in \u001B[0;36mraise_from\u001B[0;34m(value, from_value)\u001B[0m\n",
      "\u001B[0;31mNotFoundError\u001B[0m: No registered 'ResourceApplyGradientDescent' OpKernel for 'GPU' devices compatible with node {{node ResourceApplyGradientDescent}}\n\t (OpKernel was found, but attributes didn't match) Requested Attributes: T=DT_DOUBLE, use_locking=true\n\t.  Registered:  device='GPU'; T in [DT_FLOAT]\n  device='CPU'; T in [DT_HALF]\n  device='CPU'; T in [DT_BFLOAT16]\n  device='CPU'; T in [DT_FLOAT]\n  device='CPU'; T in [DT_DOUBLE]\n  device='CPU'; T in [DT_COMPLEX64]\n  device='CPU'; T in [DT_COMPLEX128]\n [Op:ResourceApplyGradientDescent]"
     ]
    }
   ],
   "source": [
    "# Gradient Function\n",
    "\n",
    "def grad(u, i, negative, r):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = pipe.model.call(u, i, negative, r)\n",
    "    # change user, item, time ids to variables\n",
    "    return loss_value, tape.gradient(loss_value, pipe.model.trainable_variables)\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "loss_value, gradients = grad(12308, 0, 1, 182)\n",
    "\n",
    "print(\"Step: {}, Loss: {}\".format(optimizer.iterations.numpy(),\n",
    "                                  pipe.model.call(12308, 0, 1, 182).numpy()))\n",
    "\n",
    "optimizer.apply_gradients(zip(gradients, pipe.model.trainable_variables))\n",
    "\n",
    "print(\"Step: {}, Loss: {}\".format(optimizer.iterations.numpy(),\n",
    "                                  pipe.model.call(12308, 0, 1, 182).numpy()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "No registered 'ResourceApplyGradientDescent' OpKernel for 'GPU' devices compatible with node {{node ResourceApplyGradientDescent}}\n\t (OpKernel was found, but attributes didn't match) Requested Attributes: T=DT_DOUBLE, use_locking=true\n\t.  Registered:  device='GPU'; T in [DT_FLOAT]\n  device='CPU'; T in [DT_HALF]\n  device='CPU'; T in [DT_BFLOAT16]\n  device='CPU'; T in [DT_FLOAT]\n  device='CPU'; T in [DT_DOUBLE]\n  device='CPU'; T in [DT_COMPLEX64]\n  device='CPU'; T in [DT_COMPLEX128]\n [Op:ResourceApplyGradientDescent]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotFoundError\u001B[0m                             Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/bd/3fcn_cld06z1y5f68_qm162m0000gn/T/ipykernel_15321/1267026885.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      7\u001B[0m         \u001B[0mnegative_item\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnegative\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mu\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mitemIDs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0muser_to_item\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m         \u001B[0mloss_value\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgradients\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgrad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mu\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnegative_item\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m         \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply_gradients\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgradients\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpipe\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrainable_variables\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     10\u001B[0m         \u001B[0mloss_per_batch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloss_value\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/general/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py\u001B[0m in \u001B[0;36mapply_gradients\u001B[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001B[0m\n\u001B[1;32m    657\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    658\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0moptimizer_utils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstrategy_supports_no_merge_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 659\u001B[0;31m         return self._distributed_apply(strategy, grads_and_vars, name,\n\u001B[0m\u001B[1;32m    660\u001B[0m                                        apply_state)\n\u001B[1;32m    661\u001B[0m       \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/general/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py\u001B[0m in \u001B[0;36m_distributed_apply\u001B[0;34m(self, distribution, grads_and_vars, name, apply_state)\u001B[0m\n\u001B[1;32m    704\u001B[0m               \u001B[0;34m\"update\"\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0meagerly_outside_functions\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;34m\"update_\"\u001B[0m \u001B[0;34m+\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    705\u001B[0m               var.op.name):\n\u001B[0;32m--> 706\u001B[0;31m             update_op = distribution.extended.update(\n\u001B[0m\u001B[1;32m    707\u001B[0m                 var, apply_grad_to_update_var, args=(grad,), group=False)\n\u001B[1;32m    708\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdistribute\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0min_cross_replica_context\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/general/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\u001B[0m in \u001B[0;36mupdate\u001B[0;34m(self, var, fn, args, kwargs, group)\u001B[0m\n\u001B[1;32m   2590\u001B[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001B[1;32m   2591\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_container_strategy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mscope\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2592\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_update\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvar\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgroup\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2593\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2594\u001B[0m       return self._replica_ctx_update(\n",
      "\u001B[0;32m~/miniforge3/envs/general/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\u001B[0m in \u001B[0;36m_update\u001B[0;34m(self, var, fn, args, kwargs, group)\u001B[0m\n\u001B[1;32m   3644\u001B[0m     \u001B[0;31m# The implementations of _update() and _update_non_slot() are identical\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3645\u001B[0m     \u001B[0;31m# except _update() passes `var` as the first argument to `fn()`.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3646\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_update_non_slot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvar\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mvar\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mtuple\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgroup\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3647\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3648\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m_update_non_slot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcolocate_with\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshould_group\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/general/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\u001B[0m in \u001B[0;36m_update_non_slot\u001B[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001B[0m\n\u001B[1;32m   3650\u001B[0m     \u001B[0;31m# once that value is used for something.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3651\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mUpdateContext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcolocate_with\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3652\u001B[0;31m       \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3653\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0mshould_group\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3654\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/general/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    595\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    596\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mag_ctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mControlStatusCtx\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstatus\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mag_ctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mStatus\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mUNSPECIFIED\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 597\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    598\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    599\u001B[0m   \u001B[0;32mif\u001B[0m \u001B[0minspect\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0misfunction\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0minspect\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mismethod\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/general/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py\u001B[0m in \u001B[0;36mapply_grad_to_update_var\u001B[0;34m(var, grad)\u001B[0m\n\u001B[1;32m    687\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0;34m\"apply_state\"\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dense_apply_args\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    688\u001B[0m         \u001B[0mapply_kwargs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"apply_state\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mapply_state\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 689\u001B[0;31m       \u001B[0mupdate_op\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_resource_apply_dense\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgrad\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvar\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mapply_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    690\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0mvar\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconstraint\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    691\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcontrol_dependencies\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mupdate_op\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/general/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py\u001B[0m in \u001B[0;36m_resource_apply_dense\u001B[0;34m(self, grad, var, apply_state)\u001B[0m\n\u001B[1;32m    139\u001B[0m           use_nesterov=self.nesterov)\n\u001B[1;32m    140\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 141\u001B[0;31m       return tf.raw_ops.ResourceApplyGradientDescent(\n\u001B[0m\u001B[1;32m    142\u001B[0m           \u001B[0mvar\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mvar\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhandle\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    143\u001B[0m           \u001B[0malpha\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcoefficients\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"lr_t\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/general/lib/python3.8/site-packages/tensorflow/python/util/tf_export.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    402\u001B[0m           \u001B[0;34m'Please pass these args as kwargs instead.'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    403\u001B[0m           .format(f=f.__name__, kwargs=f_argspec.args))\n\u001B[0;32m--> 404\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    405\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    406\u001B[0m   \u001B[0;32mreturn\u001B[0m \u001B[0mtf_decorator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmake_decorator\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdecorator_argspec\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mf_argspec\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/general/lib/python3.8/site-packages/tensorflow/python/ops/gen_training_ops.py\u001B[0m in \u001B[0;36mresource_apply_gradient_descent\u001B[0;34m(var, alpha, delta, use_locking, name)\u001B[0m\n\u001B[1;32m   1938\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0m_result\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1939\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0m_core\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1940\u001B[0;31m       \u001B[0m_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraise_from_not_ok_status\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1941\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0m_core\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_FallbackException\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1942\u001B[0m       \u001B[0;32mpass\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/general/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001B[0m in \u001B[0;36mraise_from_not_ok_status\u001B[0;34m(e, name)\u001B[0m\n\u001B[1;32m   6939\u001B[0m   \u001B[0mmessage\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmessage\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;34m\" name: \"\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;34m\"\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6940\u001B[0m   \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 6941\u001B[0;31m   \u001B[0msix\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraise_from\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_status_to_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcode\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmessage\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   6942\u001B[0m   \u001B[0;31m# pylint: enable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6943\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/general/lib/python3.8/site-packages/six.py\u001B[0m in \u001B[0;36mraise_from\u001B[0;34m(value, from_value)\u001B[0m\n",
      "\u001B[0;31mNotFoundError\u001B[0m: No registered 'ResourceApplyGradientDescent' OpKernel for 'GPU' devices compatible with node {{node ResourceApplyGradientDescent}}\n\t (OpKernel was found, but attributes didn't match) Requested Attributes: T=DT_DOUBLE, use_locking=true\n\t.  Registered:  device='GPU'; T in [DT_FLOAT]\n  device='CPU'; T in [DT_HALF]\n  device='CPU'; T in [DT_BFLOAT16]\n  device='CPU'; T in [DT_FLOAT]\n  device='CPU'; T in [DT_DOUBLE]\n  device='CPU'; T in [DT_COMPLEX64]\n  device='CPU'; T in [DT_COMPLEX128]\n [Op:ResourceApplyGradientDescent]"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "loss_per_epoch = []\n",
    "for epoch in range(1,num_epochs+1):\n",
    "    loss_per_batch = []\n",
    "    for u, i, r in data[:100]: # iterate over all interactions\n",
    "        # create negative sample\n",
    "        negative_item = negative(u, itemIDs, user_to_item)\n",
    "        loss_value, gradients = grad(u, i, negative_item, r)\n",
    "        optimizer.apply_gradients(zip(gradients, pipe.model.trainable_variables))\n",
    "        loss_per_batch.append(loss_value)\n",
    "\n",
    "        # print(\"Step: {}, Loss: {}\".format(optimizer.iterations.numpy(),\n",
    "        #                                   pipe.model.call(u, i, negative_item, r).numpy()))\n",
    "    loss_per_epoch.append(sum(loss_per_batch)/len(loss_per_batch))\n",
    "    print(\"Epoch: {}, Loss: {}\".format(epoch, loss_per_batch[-1]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [
    {
     "data": {
      "text/plain": "2490"
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_item"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}